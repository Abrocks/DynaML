<!DOCTYPE html>
<html lang="en-us">
  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      DynaML &middot; A Scala ML library
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>

  
  
  
  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      DynaML &middot; A Scala ML library
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>

  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>Library/repl for working with complex scalable ML algorithms</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/">Home</a>

    

    
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/about/">About</a>
        
      
    
      
    

    <a class="sidebar-nav-item" href="/archive/v1.2.zip">Download</a>
    <a class="sidebar-nav-item" href="">GitHub project</a>
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2015. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">DynaML</a>
            <small>A Scala ML library</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        
<p><a href="https://travis-ci.org/mandar2812/DynaML"><img src="https://travis-ci.org/mandar2812/DynaML.svg?branch=branch-1.0" alt="Build Status" /></a></p>

<h1 id="aim">Aim</h1>

<p>DynaML is a scala library/repl for implementing and working with general Machine Learning models. Machine Learning/AI applications make heavy use of various entities such as graphs, vectors, matrices etc as well as classes of mathematical models which deal with broadly three kinds of tasks, prediction, classification and clustering.</p>

<p>The aim is to build a robust set of abstract classes and interfaces, which can be extended easily to implement advanced models for small and large scale applications. But the library can also be used as an educational/research tool for multi scale data analysis. </p>

<p>Currently DynaML has implementations of Least Squares Support Vector Machine (LS-SVM) for binary classification and regression. LS-SVM is equivalent to <em>ridge regression</em>/<em>Tikhonov regularization</em>, for further background consider <a href="https://en.wikipedia.org/wiki/Least_squares_support_vector_machine">Wikipedia</a> or the <a href="http://www.amazon.com/Least-Squares-Support-Vector-Machines/dp/9812381511">book</a>.   </p>

<p>A good general introduction to Probabilistic Models for Machine Learning can be found <a href="http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/131214.pdf">here</a> in <a href="http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.HomePage">David Barberâ€™s</a> text book. The LS-SVM is equivalent to the class of models discussed in Chapter 18 (Bayesian Linear Models) of the book.</p>

<h1 id="installation">Installation</h1>
<p>Prerequisites: Maven</p>

<ul>
  <li>Clone this repository</li>
  <li>Run the following.</li>
</ul>

<div class="highlight"><pre><code class="language-text" data-lang="text">mvn clean compile
mvn package</code></pre></div>

<ul>
  <li>Make sure you give execution permission to <code>DynaML</code> in the <code>target/bin</code> directory.</li>
</ul>

<div class="highlight"><pre><code class="language-text" data-lang="text">chmod +x target/bin/DynaML
target/bin/DynaML</code></pre></div>

<p>You should get the following prompt.</p>

<div class="highlight"><pre><code class="language-text" data-lang="text">___       ___       ___       ___       ___       ___   
   /\  \     /\__\     /\__\     /\  \     /\__\     /\__\  
  /::\  \   |::L__L   /:| _|_   /::\  \   /::L_L_   /:/  /  
 /:/\:\__\  |:::\__\ /::|/\__\ /::\:\__\ /:/L:\__\ /:/__/   
 \:\/:/  /  /:;;/__/ \/|::/  / \/\::/  / \/_/:/  / \:\  \   
  \::/  /   \/__/      |:/  /    /:/  /    /:/  /   \:\__\  
   \/__/               \/__/     \/__/     \/__/     \/__/  

Welcome to DynaML v 1.2
Interactive Scala shell

DynaML&gt;</code></pre></div>

<h1 id="getting-started">Getting Started</h1>

<p>The <code>data/</code> directory contains a few sample data sets, and the root directory also has example scripts which can be executed in the shell.</p>

<ul>
  <li>First we create a linear classification model on a csv data set. We will assume that the last column in each line of the file is the target value, and we build an LS-SVM model.</li>
</ul>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">config</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span><span class="s">&quot;file&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;data/ripley.csv&quot;</span><span class="o">,</span> <span class="s">&quot;delim&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;,&quot;</span><span class="o">,</span> <span class="s">&quot;head&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;false&quot;</span><span class="o">,</span> <span class="s">&quot;task&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;classification&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">LSSVMModel</span><span class="o">(</span><span class="n">config</span><span class="o">)</span></code></pre></div>

<ul>
  <li>We can now (optionally) add a Kernel on the model to create a generalized linear Bayesian model.</li>
</ul>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">rbf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RBFKernel</span><span class="o">(</span><span class="mf">1.025</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">applyKernel</span><span class="o">(</span><span class="n">rbf</span><span class="o">)</span></code></pre></div>

<div class="highlight"><pre><code class="language-text" data-lang="text">15/08/03 19:07:42 INFO GreedyEntropySelector$: Returning final prototype set
15/08/03 19:07:42 INFO SVMKernel$: Constructing key-value representation of kernel matrix.
15/08/03 19:07:42 INFO SVMKernel$: Dimension: 13 x 13
15/08/03 19:07:42 INFO SVMKernelMatrix: Eigenvalue decomposition of the kernel matrix using JBlas.
15/08/03 19:07:42 INFO SVMKernelMatrix: Eigenvalue stats: 0.09104374173019622 =&lt; lambda =&lt; 3.110068839504519
15/08/03 19:07:42 INFO LSSVMModel: Applying Feature map to data set
15/08/03 19:07:42 INFO LSSVMModel: DONE: Applying Feature map to data set
DynaML&gt;</code></pre></div>

<ul>
  <li>Now we can solve the optimization problem posed by the LS-SVM in the parameter space. Since the LS-SVM problem is equivalent to ridge regression, we have to specify a regularization constant.</li>
</ul>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">model</span><span class="o">.</span><span class="n">setRegParam</span><span class="o">(</span><span class="mf">1.5</span><span class="o">).</span><span class="n">learn</span></code></pre></div>

<ul>
  <li>
    <p>We can now predict the value of the target variable given a new point consisting of a Vector of features using <code>model.predict()</code>.</p>
  </li>
  <li>
    <p>Evaluating models is easy in DynaML. You can create an evaluation object as follows. </p>
  </li>
</ul>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">configtest</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span><span class="s">&quot;file&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;data/ripleytest.csv&quot;</span><span class="o">,</span> <span class="s">&quot;delim&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;,&quot;</span><span class="o">,</span> <span class="s">&quot;head&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;false&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">met</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="o">(</span><span class="n">configtest</span><span class="o">)</span>
<span class="n">met</span><span class="o">.</span><span class="n">print</span></code></pre></div>

<ul>
  <li>The object <code>met</code> has a <code>print()</code> method which will dump some performance metrics in the shell. But you can also generate plots by using the <code>generatePlots()</code> method.</li>
</ul>

<div class="highlight"><pre><code class="language-text" data-lang="text">15/08/03 19:08:40 INFO BinaryClassificationMetrics: Classification Model Performance
15/08/03 19:08:40 INFO BinaryClassificationMetrics: ============================
15/08/03 19:08:40 INFO BinaryClassificationMetrics: Accuracy: 0.6172839506172839
15/08/03 19:08:40 INFO BinaryClassificationMetrics: Area under ROC: 0.2019607843137254</code></pre></div>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">met</span><span class="o">.</span><span class="n">generatePlots</span></code></pre></div>

<p><img src="https://mandar2812.github.com/DynaML/public/Screenshot.png" alt="Plots" /></p>

<ul>
  <li>
    <p>Although kernel based models allow great flexibility in modeling non linear behavior in data, they are highly sensitive to the values of their hyper-parameters. For example if we use a Radial Basis Function (RBF) Kernel, it is a non trivial problem to find the best values of the kernel bandwidth and the regularization constant.</p>
  </li>
  <li>
    <p>In order to find the best hyper-parameters for a general kernel based supervised learning model, we use methods in gradient free global optimization. This is relevant because the cost (objective) function for the hyper-parameters is not smooth in general. In fact in most common scenarios the objective function is defined in terms of some kind of cross validation performance.</p>
  </li>
  <li>
    <p>DynaML has a robust global optimization API, currently Coupled Simulated Annealing and Grid Search algorithms are implemented, the API in the package <code>org.kuleven.esat.optimization</code> can be extended to implement any general gradient or gradient free optimization methods.</p>
  </li>
  <li>
    <p>Lets tune an RBF kernel on the Ripley data.</p>
  </li>
</ul>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">com.tinkerpop.blueprints.Graph</span>
<span class="k">import</span> <span class="nn">com.tinkerpop.frames.FramedGraph</span>
<span class="k">import</span> <span class="nn">io.github.mandar2812.dynaml.graphutils.CausalEdge</span>
<span class="k">val</span> <span class="o">(</span><span class="n">optModel</span><span class="o">,</span> <span class="n">optConfig</span><span class="o">)</span> <span class="k">=</span> <span class="nc">KernelizedModel</span><span class="o">.</span><span class="n">getOptimizedModel</span><span class="o">[</span><span class="kt">FramedGraph</span><span class="o">[</span><span class="kt">Graph</span><span class="o">]</span>,
<span class="kt">Iterable</span><span class="o">[</span><span class="kt">CausalEdge</span><span class="o">]</span>, <span class="kt">model.</span><span class="k">type</span><span class="o">](</span><span class="n">model</span><span class="o">,</span> <span class="s">&quot;csa&quot;</span><span class="o">,</span>
<span class="s">&quot;RBF&quot;</span><span class="o">,</span> <span class="mi">13</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mf">0.3</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span></code></pre></div>

<p>We see a long list of logs which end in something like the snippet below, the Coupled Simulated Annealing model, gives us a set of hyper-parameters and their values. </p>

<div class="highlight"><pre><code class="language-text" data-lang="text">optModel: io.github.mandar2812.dynaml.models.svm.LSSVMModel = io.github.mandar2812.dynaml.models.svm.LSSVMModel@3662a98a
optConfig: scala.collection.immutable.Map[String,Double] = Map(bandwidth -&gt; 3.824956165264642, RegParam -&gt; 12.303758608075587)</code></pre></div>

<p>To inspect the performance of this kernel model on an independent test set, we can use the <code>model.evaluate()</code> function. But before that we must train this â€˜optimizedâ€™ kernel model on the training set.</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">optModel</span><span class="o">.</span><span class="n">setMaxIterations</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="n">learn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">met</span> <span class="k">=</span> <span class="n">optModel</span><span class="o">.</span><span class="n">evaluate</span><span class="o">(</span><span class="n">configtest</span><span class="o">)</span>
<span class="n">met</span><span class="o">.</span><span class="n">print</span><span class="o">()</span>
<span class="n">met</span><span class="o">.</span><span class="n">generatePlots</span><span class="o">()</span></code></pre></div>

<p>And the evaluation results follow â€¦</p>

<div class="highlight"><pre><code class="language-text" data-lang="text">15/08/03 19:10:13 INFO BinaryClassificationMetrics: Classification Model Performance
15/08/03 19:10:13 INFO BinaryClassificationMetrics: ============================
15/08/03 19:10:13 INFO BinaryClassificationMetrics: Accuracy: 0.8765432098765432
15/08/03 19:10:13 INFO BinaryClassificationMetrics: Area under ROC: 0.9143790849673203</code></pre></div>

<h1 id="documentation">Documentation</h1>
<p>You can refer to the project <a href="https://mandar2812.github.com/DynaML/target/site/scaladocs/index.html#package">documentation</a> for getting started with DynaML. Bear in mind that this is still at its infancy and there will be many more improvements/tweaks in the future.</p>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
